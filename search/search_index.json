{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Code Snippets (By Debasis Das) Here we will cover basic to advanced topics on the following Python Machine Learning Design Patterns Algorithms Data Structure Cocoa Swift","title":"Home"},{"location":"#welcome-to-code-snippets-by-debasis-das","text":"Here we will cover basic to advanced topics on the following Python Machine Learning Design Patterns Algorithms Data Structure Cocoa Swift","title":"Welcome to Code Snippets (By Debasis Das)"},{"location":"Cocoa/Cocoa/","text":"Cocoa Sample Code User Interface Elements NSTableView NSOutlineView NSCollectionView","title":"Cocoa"},{"location":"Cocoa/Cocoa/#cocoa-sample-code","text":"","title":"Cocoa Sample Code"},{"location":"Cocoa/Cocoa/#user-interface-elements","text":"NSTableView NSOutlineView NSCollectionView","title":"User Interface Elements"},{"location":"Datastructures/Datastructures/","text":"Data Structures Stack Stack is one of the simplest data structures. Stack has LIFO - Last In first out order Stack is like an array but with limited functionality Push to add a new object to the top Pop to remove the last object top to look at the top most/last element without removing it Swift - Stack Implementation Tree Tree is a simple data structure used to represent hierarchies such as Org Hierarchy Class Hierarchy Family Tree etc Swift - Tree Implementation","title":"Introduction"},{"location":"Datastructures/Datastructures/#data-structures","text":"","title":"Data Structures"},{"location":"Datastructures/Datastructures/#stack","text":"Stack is one of the simplest data structures. Stack has LIFO - Last In first out order Stack is like an array but with limited functionality Push to add a new object to the top Pop to remove the last object top to look at the top most/last element without removing it Swift - Stack Implementation","title":"Stack"},{"location":"Datastructures/Datastructures/#tree","text":"Tree is a simple data structure used to represent hierarchies such as Org Hierarchy Class Hierarchy Family Tree etc Swift - Tree Implementation","title":"Tree"},{"location":"Datastructures/Stack/","text":"Stack is one of the simplest data structures. Stack has LIFO - Last In first out order Stack is like an array but with limited functionality Push to add a new object to the top Pop to remove the last object top to look at the top most/last element without removing it import Cocoa //Here the stack is created as a wrapper around a swift array that allows push an object to the stack, //pop the last object and look at the top element of the stack public struct Stack < T > { fileprivate var array = [ T ]() public var isEmpty : Bool { return array . isEmpty } public var count : Int { return array . count } public mutating func push ( _ element : T ){ array . append ( element ) } public mutating func pop () -> T ?{ return array . popLast () } public var top : T ? { return array . last } } Testing the stack implementation var stack = Stack < Int >() stack . push ( 10 ) print ( stack ) //Stack<Int>(array: [10]) stack . push ( 20 ) print ( stack ) //Stack<Int>(array: [10, 20]) stack . push ( 30 ) print ( stack ) //Stack<Int>(array: [10, 20, 30]) if let val = stack . pop (){ print ( \"The popped item = \\( val ) \" ) //The popped item = 30 } print ( stack ) //Stack<Int>(array: [10, 20]) if let topElement = stack . top { print ( \"The Top Element is = \\( topElement ) \" ) } //The Top Element is = 20 print ( stack ) //Stack<Int>(array: [10, 20]) //The pop removes the last element however the top only looks at the last element without removing it.","title":"Stack"},{"location":"Datastructures/Tree/","text":"Tree Datastructure implementation in Swift import Cocoa class Node { var value : String = \"\" var children : [ Node ] = [] weak var parent : Node ? init ( value : String ) { self . value = value } func addChild ( child : Node ){ self . children . append ( child ) child . parent = self } func search ( value : String ) -> Node ?{ if value == self . value { return self } for child in self . children { if let foundObj = child . search ( value : value ){ return foundObj } } return nil } } extension Node : CustomStringConvertible { var description : String { var text = \" \\( value ) \" if ! children . isEmpty { text = text + \" \\n\\t Children = {\" for child in children { text = text + child . description + \",\" } text = text + \"} \" } return text } } Lets create some nodes and create a family tree structure let starks = Node ( value : \"Rickard Stark\" ) let s1 = Node ( value : \"Eddard Stark\" ) let s2 = Node ( value : \"Brandon Stark\" ) let s3 = Node ( value : \"Benjen Stark\" ) let c1 = Node ( value : \"Robb Stark\" ) let c2 = Node ( value : \"Sansa Stark\" ) let c3 = Node ( value : \"Arya Stark\" ) let c4 = Node ( value : \"Brandon Stark\" ) let c5 = Node ( value : \"Rickon Stark\" ) s1 . children = [ c1 , c2 , c3 , c4 , c5 ] starks . addChild ( child : s1 ) starks . addChild ( child : s2 ) starks . addChild ( child : s3 ) Lets print the entire family tree for Rickard Stark print ( starks ) Rickard Stark Children = { Eddard Stark Children = { Robb Stark , Sansa Stark , Arya Stark , Brandon Stark , Rickon Stark ,} , Brandon Stark , Benjen Stark ,} Lets print the entire family tree for Eddard Stark print ( s1 ) Eddard Stark Children = { Robb Stark , Sansa Stark , Arya Stark , Brandon Stark , Rickon Stark ,} Below we are checking if Arya Stark exists in the family tree of starks if let aryaStark = starks . search ( value : \"Arya Stark\" ) { print ( \"Found \\( aryaStark ) \" ) } else { print ( \"Not able to find Arya Stark\" ) } /* Found Arya Stark */ Lets check if John Snow belongs to the Stark family if let johnsnow = starks . search ( value : \"John Snow\" ) { print ( \"Found \\( johnsnow ) \" ) } else { print ( \"Not able to find John Snow\" ) } //Not able to find John Snow","title":"Tree"},{"location":"Datastructures/Tree/#tree-datastructure-implementation-in-swift","text":"import Cocoa class Node { var value : String = \"\" var children : [ Node ] = [] weak var parent : Node ? init ( value : String ) { self . value = value } func addChild ( child : Node ){ self . children . append ( child ) child . parent = self } func search ( value : String ) -> Node ?{ if value == self . value { return self } for child in self . children { if let foundObj = child . search ( value : value ){ return foundObj } } return nil } } extension Node : CustomStringConvertible { var description : String { var text = \" \\( value ) \" if ! children . isEmpty { text = text + \" \\n\\t Children = {\" for child in children { text = text + child . description + \",\" } text = text + \"} \" } return text } } Lets create some nodes and create a family tree structure let starks = Node ( value : \"Rickard Stark\" ) let s1 = Node ( value : \"Eddard Stark\" ) let s2 = Node ( value : \"Brandon Stark\" ) let s3 = Node ( value : \"Benjen Stark\" ) let c1 = Node ( value : \"Robb Stark\" ) let c2 = Node ( value : \"Sansa Stark\" ) let c3 = Node ( value : \"Arya Stark\" ) let c4 = Node ( value : \"Brandon Stark\" ) let c5 = Node ( value : \"Rickon Stark\" ) s1 . children = [ c1 , c2 , c3 , c4 , c5 ] starks . addChild ( child : s1 ) starks . addChild ( child : s2 ) starks . addChild ( child : s3 ) Lets print the entire family tree for Rickard Stark print ( starks ) Rickard Stark Children = { Eddard Stark Children = { Robb Stark , Sansa Stark , Arya Stark , Brandon Stark , Rickon Stark ,} , Brandon Stark , Benjen Stark ,} Lets print the entire family tree for Eddard Stark print ( s1 ) Eddard Stark Children = { Robb Stark , Sansa Stark , Arya Stark , Brandon Stark , Rickon Stark ,} Below we are checking if Arya Stark exists in the family tree of starks if let aryaStark = starks . search ( value : \"Arya Stark\" ) { print ( \"Found \\( aryaStark ) \" ) } else { print ( \"Not able to find Arya Stark\" ) } /* Found Arya Stark */ Lets check if John Snow belongs to the Stark family if let johnsnow = starks . search ( value : \"John Snow\" ) { print ( \"Found \\( johnsnow ) \" ) } else { print ( \"Not able to find John Snow\" ) } //Not able to find John Snow","title":"Tree Datastructure implementation in Swift"},{"location":"MachineLearning/DBScan_Clustering/DBScan_Clustering/","text":"DBScan Clustering Sample Created By: Debasis Das (26-Aug-2021) In this post we will generate a DBScan cluster using SKLearn DBSCAN module and will generate the following List of noise/outlier points (not readily available in DBSCAN model output) Index of noise/outlier points View the clusters by cluster label and identify all the core points in the clusters All the core points, count of core point, indexes of the core points Estimated number of clusters Silhouette Score of the Clustering Silhouette Score of the Clustering by ignoring the noise points Note: the noise points are those with label -1 import numpy as np from sklearn.cluster import DBSCAN from sklearn.metrics import silhouette_samples , silhouette_score import matplotlib.pyplot as plt epsilon = 3 min_samples = 2 X = [ [ 1 , 2 ], [ 2 , 2 ], [ 2 , 3 ], [ 8 , 7 ], [ 8 , 8 ], [ 25 , 80 ]] # plot A = np . array ( X ) plt . scatter ( A [:, 0 ], A [:, 1 ], c = 'white' , marker = 'o' , edgecolor = 'red' , s = 50 ) print ( \"The points prior to running DBScan Clustering\" ) plt . show () db = DBSCAN ( eps = epsilon , min_samples = min_samples ) . fit ( X ) core_samples_mask = np . zeros_like ( db . labels_ , dtype = bool ) core_samples_mask [ db . core_sample_indices_ ] = True labels = db . labels_ no_clusters = len ( np . unique ( labels ) ) no_noise = np . sum ( np . array ( labels ) == - 1 , axis = 0 ) noise_index = [] for i in range ( len ( labels )): if labels [ i ] == - 1 : noise_index . append ( i ) print ( \"Noise/Outliers Index are at the following indexes \" , noise_index ) for obj in noise_index : print ( \"Noise/outlier point = \" , X [ obj ]) print ( \"-\" * 20 ) unique_labels = set ( labels ) print ( \"unique labels are \" , unique_labels ) print ( \"-\" * 20 ) for label in unique_labels : print ( \"cluster points for \" , label ) cluster_indexes = [] for i in range ( len ( labels )): if labels [ i ] == label : cluster_indexes . append ( i ) print ( \"cluster_indexes = \" , cluster_indexes ) for obj in cluster_indexes : print ( \"exact point = \" , X [ obj ]) print ( \"-\" * 10 ) silhouette_avg = silhouette_score ( X , labels ) print ( \"-\" * 20 ) print ( \"Labels \" , labels ) print ( \"Indices of Core Samples = \" , db . core_sample_indices_ ) print ( \"Copy of each core sample found by training = \" , db . components_ ) print ( \"Count of Core Samples \" , len ( db . core_sample_indices_ )) print ( 'Estimated no. of clusters: %d ' % no_clusters ) print ( 'Estimated no. of noise points: %d ' % no_noise ) print ( \"-\" * 20 ) print ( \"silhouette_avg = \" , silhouette_avg ) print ( \"Silhoutter Avg ignoring noise points \" ,( silhouette_avg * len ( labels )) / ( len ( labels ) - no_noise ) ) The points prior to running DBScan Clustering Noise/Outliers Index are at the following indexes [5] Noise/outlier point = [25, 80] -------------------- unique labels are {0, 1, -1} -------------------- cluster points for 0 cluster_indexes = [0, 1, 2] exact point = [1, 2] exact point = [2, 2] exact point = [2, 3] ---------- cluster points for 1 cluster_indexes = [3, 4] exact point = [8, 7] exact point = [8, 8] ---------- cluster points for -1 cluster_indexes = [5] exact point = [25, 80] ---------- -------------------- Labels [ 0 0 0 1 1 -1] Indices of Core Samples = [0 1 2 3 4] Copy of each core sample found by training = [[1 2] [2 2] [2 3] [8 7] [8 8]] Count of Core Samples 5 Estimated no. of clusters: 3 Estimated no. of noise points: 1 -------------------- silhouette_avg = 0.7227526416896678 Silhoutter Avg ignoring noise points 0.8673031700276013","title":"DBScan Clustering(SKLearn)"},{"location":"MachineLearning/DBScan_Clustering/DBScan_Clustering/#dbscan-clustering-sample","text":"Created By: Debasis Das (26-Aug-2021) In this post we will generate a DBScan cluster using SKLearn DBSCAN module and will generate the following List of noise/outlier points (not readily available in DBSCAN model output) Index of noise/outlier points View the clusters by cluster label and identify all the core points in the clusters All the core points, count of core point, indexes of the core points Estimated number of clusters Silhouette Score of the Clustering Silhouette Score of the Clustering by ignoring the noise points Note: the noise points are those with label -1 import numpy as np from sklearn.cluster import DBSCAN from sklearn.metrics import silhouette_samples , silhouette_score import matplotlib.pyplot as plt epsilon = 3 min_samples = 2 X = [ [ 1 , 2 ], [ 2 , 2 ], [ 2 , 3 ], [ 8 , 7 ], [ 8 , 8 ], [ 25 , 80 ]] # plot A = np . array ( X ) plt . scatter ( A [:, 0 ], A [:, 1 ], c = 'white' , marker = 'o' , edgecolor = 'red' , s = 50 ) print ( \"The points prior to running DBScan Clustering\" ) plt . show () db = DBSCAN ( eps = epsilon , min_samples = min_samples ) . fit ( X ) core_samples_mask = np . zeros_like ( db . labels_ , dtype = bool ) core_samples_mask [ db . core_sample_indices_ ] = True labels = db . labels_ no_clusters = len ( np . unique ( labels ) ) no_noise = np . sum ( np . array ( labels ) == - 1 , axis = 0 ) noise_index = [] for i in range ( len ( labels )): if labels [ i ] == - 1 : noise_index . append ( i ) print ( \"Noise/Outliers Index are at the following indexes \" , noise_index ) for obj in noise_index : print ( \"Noise/outlier point = \" , X [ obj ]) print ( \"-\" * 20 ) unique_labels = set ( labels ) print ( \"unique labels are \" , unique_labels ) print ( \"-\" * 20 ) for label in unique_labels : print ( \"cluster points for \" , label ) cluster_indexes = [] for i in range ( len ( labels )): if labels [ i ] == label : cluster_indexes . append ( i ) print ( \"cluster_indexes = \" , cluster_indexes ) for obj in cluster_indexes : print ( \"exact point = \" , X [ obj ]) print ( \"-\" * 10 ) silhouette_avg = silhouette_score ( X , labels ) print ( \"-\" * 20 ) print ( \"Labels \" , labels ) print ( \"Indices of Core Samples = \" , db . core_sample_indices_ ) print ( \"Copy of each core sample found by training = \" , db . components_ ) print ( \"Count of Core Samples \" , len ( db . core_sample_indices_ )) print ( 'Estimated no. of clusters: %d ' % no_clusters ) print ( 'Estimated no. of noise points: %d ' % no_noise ) print ( \"-\" * 20 ) print ( \"silhouette_avg = \" , silhouette_avg ) print ( \"Silhoutter Avg ignoring noise points \" ,( silhouette_avg * len ( labels )) / ( len ( labels ) - no_noise ) ) The points prior to running DBScan Clustering Noise/Outliers Index are at the following indexes [5] Noise/outlier point = [25, 80] -------------------- unique labels are {0, 1, -1} -------------------- cluster points for 0 cluster_indexes = [0, 1, 2] exact point = [1, 2] exact point = [2, 2] exact point = [2, 3] ---------- cluster points for 1 cluster_indexes = [3, 4] exact point = [8, 7] exact point = [8, 8] ---------- cluster points for -1 cluster_indexes = [5] exact point = [25, 80] ---------- -------------------- Labels [ 0 0 0 1 1 -1] Indices of Core Samples = [0 1 2 3 4] Copy of each core sample found by training = [[1 2] [2 2] [2 3] [8 7] [8 8]] Count of Core Samples 5 Estimated no. of clusters: 3 Estimated no. of noise points: 1 -------------------- silhouette_avg = 0.7227526416896678 Silhoutter Avg ignoring noise points 0.8673031700276013","title":"DBScan Clustering Sample"},{"location":"MachineLearning/KMeans_Clustering/KMeans_Clustering/","text":"KMeans Clustering using SKLearn Created By: Debasis Das (26-Aug-2021) Using SKLearn to explore KMeans Clustering and Plotting the cluster centroids along with the cluster points import pandas as pd import numpy as np from sklearn.cluster import KMeans from sklearn.decomposition import PCA import matplotlib.pyplot as plt A = [ [ 10 , 10 ], [ 11 , 10 ], [ 12 , 10 ], [ 10 , 11 ], [ 15 , 17 ], [ 13.5 , 15 ], [ 15 , 16 ], [ 17 , 18 ], [ 14.5 , 19 ], [ 20 , 20 ], [ 13.5 , 14.5 ] ] df = pd . DataFrame ( A ) number_clusters = 3 pca = PCA ( n_components = 2 ) pca . fit ( df ) x_pca = pca . fit_transform ( df ) km = KMeans ( n_clusters = number_clusters , init = 'random' , n_init = 10 , max_iter = 300 , tol = 1e-04 , random_state = 0 ) . fit ( x_pca ) kmeans_labels = km . labels_ unique_labels = np . unique ( kmeans_labels ) for i in unique_labels : plt . scatter ( x_pca [ kmeans_labels == i , 0 ], x_pca [ kmeans_labels == i , 1 ] ) cluster_centroids = km . cluster_centers_ print ( \"cluster_centroids = \" , cluster_centroids ) print ( \"kmeans_labels = \" , kmeans_labels ) plt . scatter ( cluster_centroids [:, 0 ], cluster_centroids [:, 1 ], linewidths = 3 , s = 150 , marker = \"x\" , color = 'r' ) cluster_centroids = [[ 6.38423083 -1.0142913 ] [ 1.67176795 0.63576739] [-5.28182536 -0.28756359]] kmeans_labels = [2 2 2 2 1 1 1 0 1 0 1] <matplotlib.collections.PathCollection at 0x7fef5a604c40>","title":"KMeans Clustering(SKLearn)"},{"location":"MachineLearning/KMeans_Clustering/KMeans_Clustering/#kmeans-clustering-using-sklearn","text":"Created By: Debasis Das (26-Aug-2021) Using SKLearn to explore KMeans Clustering and Plotting the cluster centroids along with the cluster points import pandas as pd import numpy as np from sklearn.cluster import KMeans from sklearn.decomposition import PCA import matplotlib.pyplot as plt A = [ [ 10 , 10 ], [ 11 , 10 ], [ 12 , 10 ], [ 10 , 11 ], [ 15 , 17 ], [ 13.5 , 15 ], [ 15 , 16 ], [ 17 , 18 ], [ 14.5 , 19 ], [ 20 , 20 ], [ 13.5 , 14.5 ] ] df = pd . DataFrame ( A ) number_clusters = 3 pca = PCA ( n_components = 2 ) pca . fit ( df ) x_pca = pca . fit_transform ( df ) km = KMeans ( n_clusters = number_clusters , init = 'random' , n_init = 10 , max_iter = 300 , tol = 1e-04 , random_state = 0 ) . fit ( x_pca ) kmeans_labels = km . labels_ unique_labels = np . unique ( kmeans_labels ) for i in unique_labels : plt . scatter ( x_pca [ kmeans_labels == i , 0 ], x_pca [ kmeans_labels == i , 1 ] ) cluster_centroids = km . cluster_centers_ print ( \"cluster_centroids = \" , cluster_centroids ) print ( \"kmeans_labels = \" , kmeans_labels ) plt . scatter ( cluster_centroids [:, 0 ], cluster_centroids [:, 1 ], linewidths = 3 , s = 150 , marker = \"x\" , color = 'r' ) cluster_centroids = [[ 6.38423083 -1.0142913 ] [ 1.67176795 0.63576739] [-5.28182536 -0.28756359]] kmeans_labels = [2 2 2 2 1 1 1 0 1 0 1] <matplotlib.collections.PathCollection at 0x7fef5a604c40>","title":"KMeans Clustering using SKLearn"},{"location":"MachineLearning/MaximumLikelihood/MaximumLikelihood/","text":"Maximum Likelihood for Normal Distribution Added By (Debasis Das - 27-Aug-2021) Notes taken from StatQuest: Maximum Likelihood, clearly explained!!! Maximum Likelihood For the Normal Distribution, step-by-step!","title":"Maximum Likelihood"},{"location":"MachineLearning/MaximumLikelihood/MaximumLikelihood/#maximum-likelihood-for-normal-distribution","text":"Added By (Debasis Das - 27-Aug-2021) Notes taken from StatQuest: Maximum Likelihood, clearly explained!!! Maximum Likelihood For the Normal Distribution, step-by-step!","title":"Maximum Likelihood for Normal Distribution"},{"location":"OS_Notes/OS_Notes/","text":"","title":"OS Notes"}]}